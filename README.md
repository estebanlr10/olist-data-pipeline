# ğŸš€ Olist E-Commerce Data Pipeline

Pipeline de procesamiento de datos end-to-end para anÃ¡lisis de ventas de e-commerce brasileÃ±o.

## ğŸ“Š DescripciÃ³n

Este proyecto implementa un pipeline completo de Data Engineering que procesa datos transaccionales de Olist (Kaggle), aplicando limpieza, transformaciones SQL, modelado dimensional y validaciones de calidad.

## ğŸ—ï¸ Arquitectura del Pipeline
```
RAW DATA â†’ INGESTA â†’ LIMPIEZA â†’ TRANSFORMACIONES â†’ MODELO ESTRELLA â†’ VALIDACIONES â†’ OUTPUTS
```

**Etapas:**
1. **Ingesta y Limpieza** (pandas): EliminaciÃ³n de nulos, duplicados, normalizaciÃ³n
2. **Transformaciones SQL** (DuckDB): Agregaciones y mÃ©tricas de negocio
3. **Modelo Estrella**: Tablas dimensionales y de hechos
4. **Validaciones**: Integridad referencial y calidad de datos

## ğŸ“ Estructura del Proyecto
```
ProyectoFinal/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Datos originales (CSV)
â”‚   â””â”€â”€ outputs/          # Datos procesados
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingesta.py        # Limpieza de datos
â”‚   â”œâ”€â”€ transformaciones.py  # SQL queries
â”‚   â”œâ”€â”€ modelo.py         # Modelo dimensional
â”‚   â””â”€â”€ validaciones.py   # Validaciones de calidad
â”œâ”€â”€ logs/                 # Logs de ejecuciÃ³n
â”œâ”€â”€ docs/                 # DocumentaciÃ³n
â”œâ”€â”€ run_pipeline.py       # Orquestador principal
â””â”€â”€ requirements.txt      # Dependencias
```

## ğŸš€ CÃ³mo Ejecutar

### 1. Clonar el repositorio
```bash
git clone https://github.com/estebanlr10/olist-data-pipeline.git
cd olist-data-pipeline
```

### 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 3. Colocar datos raw
Descargar el [Brazilian E-Commerce Dataset by Olist](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce) y colocar los CSVs en `data/raw/`

### 4. Ejecutar pipeline completo
```bash
python run_pipeline.py
```

## ğŸ“ˆ Outputs Generados

El pipeline genera 7 archivos CSV en `data/outputs/`:

**Datos Limpios:**
- `clientes_limpios.csv`
- `items_limpios.csv`
- `ordenes_limpias.csv`

**Modelo Estrella:**
- `dim_clientes.csv`
- `dim_productos.csv`
- `fact_ventas.csv`

**Reportes:**
- `ventas_mensuales.csv`

## ğŸ› ï¸ TecnologÃ­as

- **Python 3.x**
- **pandas**: ManipulaciÃ³n de datos
- **DuckDB**: Motor SQL analÃ­tico
- **pathlib**: GestiÃ³n de rutas
- **logging**: Trazabilidad

## ğŸ“ Logs

Todos los eventos del pipeline se registran en `logs/pipeline.log` con timestamps.

## ğŸ‘¤ Autor

**Esteban LÃ³pez**  
Bootcamp de Data Engineering - Ian Saura  

